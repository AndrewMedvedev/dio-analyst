"""–ú–æ–¥—É–ª—å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–µ—Ä–µ–≤–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å–∞–π—Ç–∞"""

from __future__ import annotations

from collections.abc import Iterator
from datetime import datetime
from urllib.parse import urlparse

from pydantic import BaseModel, Field, HttpUrl, field_validator
from usp.objects.page import SitemapPage
from usp.tree import sitemap_tree_for_homepage

PRIORITY_KEYWORDS: tuple[str, ...] = (
    "product",
    "services",
    "catalog",
    "category",
    "shop",
    "blog",
    "article",
    "news",
    "post",
    "about",
    "contact",
    "price",
    "buy",
    "order",
    "cases",
)
# –ó–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ endpoints
DENIED_EXTENSIONS: tuple[str, ...] = (
    ".php",
    ".asp",
    ".aspx",
    ".jsp",
    ".cgi",
    ".pdf",
    ".doc",
    ".docx",
    ".xls",
    ".xlsx",
    ".zip",
    ".rar",
    ".tar",
    ".gz",
    ".jpg",
    ".jpeg",
    ".png",
    ".gif",
    ".bmp",
    ".svg",
    ".webp",
    ".mp4",
    ".avi",
    ".mov",
    ".wmv",
    ".mp3",
    ".wav",
    ".ogg",
    ".css",
    ".js",
    ".json",
    ".xml",
)


def parse_url_path(url: str) -> list[str]:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç URL –Ω–∞ —á–∞—Å—Ç–∏.

    –ü—Ä–∏–º–µ—Ä: "http://site.com/folder/page" -> ["folder", "page"]
    """
    path = urlparse(url).path
    return [segment for segment in path.strip("/").split("/") if segment]


class TreeNode(BaseModel):
    """–£–∑–µ–ª –¥–µ—Ä–µ–≤–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü —Å–∞–π—Ç–∞"""

    name: str
    url: HttpUrl
    priority: float | None = None
    last_modified: datetime | None = None
    children: list[TreeNode] = Field(default_factory=list)

    @field_validator("last_modified", mode="before")
    @classmethod
    def validate_last_modified(cls, value: str | None) -> datetime | None:
        if not value or value is None:
            return None
        if isinstance(value, str):
            try:
                return datetime.fromisoformat(value)
            except (ValueError, AttributeError):
                return None
        return value

    @property
    def sections(self) -> list[str]:
        """–°–µ–∫—Ü–∏–∏ –≤–Ω—É—Ç—Ä–∏ –∫–æ—Ç–æ—Ä—ã—Ö –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
        url = str(self.url)
        domain = urlparse(url).netloc
        url = url.replace(domain, "").replace("http://", "").replace("https://", "")
        return url.split("/")

    @property
    def is_leaf(self) -> bool:
        """–Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ —É–∑–µ–ª –ª–∏—Å—Ç–æ–º"""
        return len(self.children) == 0

    def max_depth(self) -> int:
        """–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞"""
        if not self.children:
            return 0
        return max(child.max_depth() for child in self.children) + 1

    def count_nodes(self) -> int:
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤ –≤ –¥–µ—Ä–µ–≤–µ"""
        count = 1
        for child in self.children:
            count += child.count_nodes()
        return count

    def iter_nodes(self) -> Iterator[TreeNode]:
        """–ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –≤—Å–µ–º —É–∑–ª–∞–º –¥–µ—Ä–µ–≤–∞"""
        yield self
        for child in self.children:
            yield from child.iter_nodes()

    def iter_leaves(self) -> Iterator[TreeNode]:
        """–ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –ª–∏—Å—Ç—å—è–º –¥–µ—Ä–µ–≤–∞"""
        for node in self.iter_nodes():
            if node.is_leaf:
                yield node

    def find_node(self, url: str) -> TreeNode | None:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ –µ—ë URL"""
        if self.url == url:
            return self
        for child in self.children:
            found = child.find_node(url)
            if found:
                return found
        return None

    def to_string(self, max_depth: int | None = None) -> str:
        """–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ –≤ —á–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        lines: list[str] = []
        self.draw_tree_lines(lines, max_depth=max_depth)
        return "\n".join(lines)

    def draw_tree_lines(
        self,
        lines: list[str],
        max_depth: int | None = None,
        current_depth: int = 0,
        prefix: str = "",
        is_last: bool = True,
    ) -> None:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–µ—Ä–µ–≤–∞"""
        if max_depth is not None and current_depth >= max_depth:
            return
        meta_parts: list[str] = []
        if self.priority is not None:
            meta_parts.append(f"–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {self.priority}")
        if self.last_modified:
            meta_parts.append(f"–ü–æ—Å–ª–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {self.last_modified.strftime('%d.%m.%Y')}")
        meta_str = " [" + ", ".join(meta_parts) + "]" if meta_parts else ""
        if current_depth == 0:
            icon = "üåê"
            line = f"{icon} {self.name} ({self.url}){meta_str}"
            lines.append(line)
        else:
            icon = "üìÑ" if self.is_leaf else "üìÅ"
            connector = "‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ "
            line = f"{prefix}{connector}{icon} {self.name}{meta_str}"
            lines.append(line)
        new_prefix = prefix if current_depth == 0 else prefix + ("    " if is_last else "‚îÇ   ")
        for i, child in enumerate(self.children):
            is_last_child = i == len(self.children) - 1
            child.draw_tree_lines(lines, max_depth, current_depth + 1, new_prefix, is_last_child)

    def last_site_change(self) -> datetime | None:
        """–ü–æ—Å–ª–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –Ω–∞ —Å–∞–π—Ç–µ"""
        latest = self.last_modified
        for node in self.iter_nodes():
            if node.last_modified and (latest is None or node.last_modified > latest):
                latest = node.last_modified
        return latest

    def last_changed_node(self) -> TreeNode | None:
        """–ü–æ—Å–ª–µ–¥–Ω—è—è –∏–∑–º–µ–Ω—ë–Ω–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
        nodes: list[TreeNode] = [
            node for node in self.iter_nodes() if node.last_modified is not None
        ]
        return max(nodes, key=lambda x: x.last_modified, default=None)  # type: ignore  # noqa: PGH003

    def __hash__(self) -> int:
        return hash(self.url)

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, TreeNode):
            return False
        return self.url == other.url


def add_page_to_tree(
    base_url: HttpUrl,
    root: TreeNode,
    page: SitemapPage,
    segments: list[str],
    current_depth: int = 0,
) -> None:
    if current_depth >= len(segments):
        return
    current_segment = segments[current_depth]
    node: TreeNode | None = next(
        (child for child in root.children if child.name == current_segment), None
    )
    if node is None:
        path_part = "/".join(segments[: current_depth + 1])
        full_url = f"{str(base_url).rstrip('/')}/{path_part}"
        node = TreeNode.model_validate({
            "name": current_segment,
            "url": full_url,
            "priority": page.priority,
            "last_modified": page.last_modified,
        })
        root.children.append(node)
    add_page_to_tree(base_url, node, page, segments, current_depth + 1)


def build_site_tree(url: HttpUrl) -> TreeNode:
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å—Ç—Ä–æ–∏—Ç –¥–µ—Ä–µ–≤–æ —Å–∞–π—Ç–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º –∏–∑ sitemap.xml.

    :param url: URL –∞–¥—Ä–µ—Å —Å–∞–π—Ç–∞.
    :return –ü–æ—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –¥–µ—Ä–µ–≤–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å–∞–π—Ç–∞.
    """
    name = str(url).replace("http://", "").replace("https://", "").replace("/", "")
    root = TreeNode(name=name, url=url)
    sitemap = sitemap_tree_for_homepage(str(url), use_robots=False)
    for page in sitemap.all_pages():
        segments = parse_url_path(page.url)
        add_page_to_tree(url, root, page, segments)
    return root


def _get_path_segments(url: HttpUrl) -> list[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ URL –∞–¥—Ä–µ—Å–∞,
    –ø—Ä–∏–º–µ—Ä: 'http://example.ru/services/3' -> ['services', '3']

    :param url: –ê–¥—Ä–µ—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è.
    :return –°–µ–∫—Ü–∏–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.
    """
    parsed = urlparse(str(url))
    return [section for section in parsed.path.strip("/").split("/") if section]


def _sort_by_last_modified(nodes: list[TreeNode]) -> list[TreeNode]:
    """–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
    with_dates: list[TreeNode] = []
    without_dates: list[TreeNode] = []
    for node in nodes:
        if node.last_modified is None:
            without_dates.append(node)
        else:
            with_dates.append(node)
    with_dates.sort(key=lambda node: node.last_modified, reverse=True)  # type: ignore  # noqa: PGH003
    return with_dates + without_dates


def _is_denied_url(url: HttpUrl) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ URL –Ω–∞ –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–π, True –µ—Å–ª–∏ –∑–∞–ø—Ä–µ—â—ë–Ω, False –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à—ë–Ω"""
    return not any(
        str(url).split(".")[-1].lower().endswith(extension) for extension in DENIED_EXTENSIONS
    )


def _get_node_sort_key(node: TreeNode) -> tuple[float, float, float]:
    """–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —É–∑–ª–æ–≤
    - –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏–∑ sitemap.xml (–µ—Å–ª–∏ –µ—Å—Ç—å)
    - –î–∞—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è (—Å–Ω–∞—á–∞–ª–∞ –Ω–æ–≤—ã–µ)
    - –ì–ª—É–±–∏–Ω–∞ —É–∑–ª–∞ (–º–∞–ª–∞—è –≥–ª—É–±–∏–Ω–∞ —Å–Ω–∞—á–∞–ª–∞)
    """
    priority_score = node.priority if node.priority is not None else 0.5
    date_score = node.last_modified.timestamp() if node.last_modified else 0
    depth_penalty = len(_get_path_segments(node.url)) * 0.01
    return -priority_score, -date_score, depth_penalty


def extract_key_pages(  # noqa: C901
    tree: TreeNode, key_segments: list[str], max_result: int = 15
) -> list[HttpUrl]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –∫–ª—é—á–µ–≤—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü —Å–∞–π—Ç–∞.

    :param tree: –î–µ—Ä–µ–≤–æ —Å–∞–π—Ç–∞.
    :param key_segments: –ö–ª—é—á–µ–≤—ã–µ —Å–µ–∫—Ü–∏–∏ —Å–∞–π—Ç–∞ –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç—å.
    :param max_result: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ–∫–∞–µ–º—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü.
    :return –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ URL –∞–¥—Ä–µ—Å–∞ —Å–∞–π—Ç–∞.
    """
    key_pages: set[HttpUrl] = {tree.url}  # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–∞–π—Ç–∞
    nodes_with_key_segments: list[TreeNode] = []  # –£–∑–ª—ã —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
    used_segments: set[str] = set()  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥–≤–æ–π–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∏–∑–º–µ–Ω—ë–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    last_changed_node = tree.last_changed_node()
    if last_changed_node is not None:
        key_pages.add(last_changed_node.url)
    for node in tree.iter_nodes():
        if len(key_pages) > max_result:
            break
        segments = _get_path_segments(node.url)
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ –ø—É—Ç–∏
        has_key_segment = any(key_segment in segments for key_segment in key_segments)
        if has_key_segment and _is_denied_url(node.url):
            nodes_with_key_segments.append(node)
    nodes_with_key_segments.sort(key=_get_node_sort_key)
    for node_with_key_segment in nodes_with_key_segments:
        if len(key_pages) >= max_result:
            break
        segments = _get_path_segments(node_with_key_segment.url)
        # –ù–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —É–∑–ª–µ
        found_key_segment = next(
            (key_segment for key_segment in key_segments if key_segment in segments), None
        )
        if found_key_segment is not None and found_key_segment not in used_segments:
            key_pages.add(node_with_key_segment.url)
            used_segments.add(found_key_segment)
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–≤–µ–∂–∏—Ö –¥–æ—á–µ—Ä–Ω–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            if not node_with_key_segment.is_leaf:
                children = _sort_by_last_modified(node_with_key_segment.children)
                for child in children:
                    if len(key_pages) < max_result and _is_denied_url(child.url):
                        key_pages.add(child.url)
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞–±—Ä–∞–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü, —Ç–æ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –ª–∏—Å—Ç—å—è
    if len(key_pages) < max_result:
        leaves = list(tree.iter_leaves())
        leaves.sort(key=_get_node_sort_key)
        key_pages.update(leaf.url for leaf in leaves[: max_result - len(key_pages)])
    return list(key_pages)
